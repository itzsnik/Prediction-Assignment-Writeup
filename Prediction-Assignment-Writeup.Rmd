---
title: "Prediction-Assignment-Writeup"
author: "Nitish Kumar"
date: "2023-05-20"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Practical Machine Learning Project

## Background

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement ??? a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset).

## Importing libraries

```{r warning=FALSE}
library(caret)
library(dplyr)
library(AppliedPredictiveModeling)
library(randomForest)
```


## Data

The training data for this project are available here:

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

The test data are available here:

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv


## Analysis

Loading data
```{r}
training = read.csv("./pml-training.csv",na.strings=c("NA","#DIV/0!",""))
testing = read.csv("./pml-testing.csv",na.strings=c("NA","#DIV/0!",""))
```

## Data Dimensions
```{r}
dim(training)
dim(testing)
```
## First look at the data
```{r}
head(training)
head(testing)
```
The str() and table() functions are used to understand the basic structure of the dataset. Due to the high number of columns (160), the result is subsetted:
```{r}
ncol(training)
```
```{r}
str(training[,1:10]) # fist 10 columns. The first variables are not actual predictors
```
```{r}
str(training[,149:160]) # last 12 columns. The outcome Classe appears at the end. Some columns appear to have plenty of NAs. 
```
#### Number of observations per "user_name" and per "classe"
```{r}
table(training$classe,training$user_name) 
```
```{r}
ggplot(training, aes(classe)) + geom_bar(fill = "steelblue") + ggtitle("Counts per classe")
```
The plot shows that there is a relatively balanced distribution of observations among “classe” types.

#### Data pre-processing

The outcome “classe” must be converted into a factor variable. Additionally, there are many columns which do not provide any relevant information, because they either have plenty of NAs or because they are not actual predictors obtained from accelerator measurements. Those columns will be removed:
```{r}
training$classe <- as.factor(training$classe) # classe is converted into a factor variable.

trainingPrep <- training %>% select(8:160) # Non-predictors are removed.

trainingPrep <- trainingPrep %>% select_if(colSums(is.na(trainingPrep)) < 19000) # Only the columns with LESS than 19000 NAs are left (total nr. of obs. is 19622)

ncol(trainingPrep) # The resulting amount of columns in the dataset is 53.
```
#### Create Data Partition
The dataset is further divided into train(75%) and test(25%) parts for cross-validation:
```{r}
inTrain = createDataPartition(trainingPrep$classe,p=3/4)[[1]]
trainPart = trainingPrep[inTrain,]
testPart = trainingPrep[-inTrain,]
```
#### Model training
A couple of models will be trained and tested with cross validation to find out which of them has the highest accuracy level. More precisely, a random forest model and an LDA model will be tested:
```{r}
set.seed(1234)
modfitrf <- randomForest(classe~., method = "class", data = trainPart)
predrf <- predict(modfitrf, newdata = testPart, type = "class")
confusionMatrix(predrf, testPart$classe)
```
```{r}
set.seed(1234)
modfitlda <- train(classe ~ ., method = "lda", data = trainPart)
predlda <- predict(modfitlda, newdata = testPart)
confusionMatrix(predlda, testPart$classe)
```
#### Model selection
The accuracy level of the random forest model (higher than 99%) is clearly higher than that of the LDA model(close to 70%). Therefore, the random forest model is selected.

#### Cross validation and expected out of sample error.
The output of sample error (calculated as 1- Accuracy Level) is below 1%, therefore very low.

#### Prediction on 20 test cases
```{r}
predrf20 <- predict(modfitrf,newdata = testing,type = "class")
print(predrf20)
```
This is the prediction achieved with the selected model (random forest) for the 20 test cases.
